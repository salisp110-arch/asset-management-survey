# app.py
# -*- coding: utf-8 -*-
import os, json, base64
import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
from datetime import datetime

# scikit-learn Ø§Ø®ØªÛŒØ§Ø±ÛŒ
try:
    from sklearn.cluster import KMeans
    SKLEARN_OK = True
except Exception:
    SKLEARN_OK = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§ÛŒÙ‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Ù¾Ø±Ø³Ø´Ù†Ø§Ù…Ù‡ Ùˆ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø±Ø§ÛŒÛŒ", layout="wide")
BASE = Path(".")
DATA_DIR = BASE / "data"
ASSETS_DIR = BASE / "assets"
DATA_DIR.mkdir(exist_ok=True)
ASSETS_DIR.mkdir(exist_ok=True)

# ØªÙ… Ùˆ ÙÙˆÙ†Øª (Vazir + fallback Ø¨Ù‡ Vazirmatn)
st.markdown("""
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/rastikerdar/vazir-font@v30.1.0/dist/font-face.css">
<style>
/* Ø³Ø±Ø§Ø³Ø±ÛŒ: Ù‡Ù…Ù‡ Ø¹Ù†Ø§ØµØ± Ù…Ø¬Ø¨ÙˆØ± Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Vazir */
:root{ --app-font: Vazir, Tahoma, Arial, sans-serif; }
html, body, * { font-family: var(--app-font) !important; direction: rtl; }

/* Ú©Ù…ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú†ÛŒÙ†Ø´ Ú©Ù„ÛŒ */
.block-container { padding-top: .6rem; padding-bottom: 3rem; }
h1,h2,h3,h4 { color:#16325c; }

/* Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ Ùˆ KPIÙ‡Ø§ (Ù…Ø«Ù„ Ù‚Ø¨Ù„ØŒ Ø¨Ø§ ÙÙˆÙ†Øª Ø¬Ø¯ÛŒØ¯) */
.question-card {
  background: rgba(255,255,255,0.78);
  backdrop-filter: blur(6px);
  padding: 18px 20px; margin: 10px 0 18px 0;
  border-radius: 14px; border: 1px solid #e8eef7;
  box-shadow: 0 6px 16px rgba(36,74,143,0.08), inset 0 1px 0 rgba(255,255,255,0.7);
}
.q-head{ font-weight:700; color:#16325c; font-size:16px; margin-bottom:8px; }
.q-desc{ color:#4a5e85; font-size:14px; line-height:1.9; margin-bottom:10px; }
.q-num{ display:inline-block; background:#e8f0fe; color:#16325c; font-weight:700; border-radius:8px; padding:2px 8px; margin-left:6px; font-size:12px; }

.kpi{
  border-radius:14px; padding:16px 18px; border:1px solid #e6ecf5;
  background:linear-gradient(180deg,#ffffff 0%,#f6f9ff 100%);
  box-shadow:0 8px 20px rgba(0,0,0,0.05); min-height:96px;
}
.kpi .title{ color:#456; font-size:13px; margin-bottom:6px; }
.kpi .value{ color:#0f3b8f; font-size:22px; font-weight:800; }
.kpi .sub{ color:#6b7c93; font-size:12px; }
</style>
""", unsafe_allow_html=True)


PLOTLY_TEMPLATE = "plotly_white"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOPICS_PATH = BASE / "topics.json"
if not TOPICS_PATH.exists():
    st.error("ÙØ§ÛŒÙ„ topics.json Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ø¢Ù† Ø±Ø§ Ú©Ù†Ø§Ø± app.py Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
    st.stop()
TOPICS = json.loads(TOPICS_PATH.read_text(encoding="utf-8"))
if len(TOPICS) != 40:
    st.warning("âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Û´Û° Ø¨Ø§Ø´Ø¯ ØªØ§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ ÙØ§Ø²ÛŒ Ø¯Ø±Ø³Øª Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÙˆØ¯.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ù†Ù‚Ø´â€ŒÙ‡Ø§ Ùˆ Ø±Ù†Ú¯â€ŒÙ‡Ø§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROLES = [
    "Ù…Ø¯ÛŒØ±Ø§Ù† Ø§Ø±Ø´Ø¯",
    "Ù…Ø¯ÛŒØ±Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒÛŒ",
    "Ø³Ø±Ù¾Ø±Ø³ØªØ§Ù† / Ø®Ø¨Ø±Ú¯Ø§Ù†",
    "Ù…ØªØ®ØµØµØ§Ù† ÙÙ†ÛŒ",
    "Ù…ØªØ®ØµØµØ§Ù† ØºÛŒØ± ÙÙ†ÛŒ",
]
ROLE_COLORS = {
    "Ù…Ø¯ÛŒØ±Ø§Ù† Ø§Ø±Ø´Ø¯":"#d62728",
    "Ù…Ø¯ÛŒØ±Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒÛŒ":"#1f77b4",
    "Ø³Ø±Ù¾Ø±Ø³ØªØ§Ù† / Ø®Ø¨Ø±Ú¯Ø§Ù†":"#2ca02c",
    "Ù…ØªØ®ØµØµØ§Ù† ÙÙ†ÛŒ":"#ff7f0e",
    "Ù…ØªØ®ØµØµØ§Ù† ØºÛŒØ± ÙÙ†ÛŒ":"#9467bd"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø³Ø® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LEVEL_OPTIONS = [
    ("Ø§Ø·Ù„Ø§Ø¹ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¯Ø§Ø±Ù….", 0),
    ("Ø³Ø§Ø²Ù…Ø§Ù† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø±Ø¯Ù‡ ÙˆÙ„ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¢Ù† Ø±Ø§ Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†Ù….", 1),
    ("Ø³Ø§Ø²Ù…Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ ØªØ¯ÙˆÛŒÙ† Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø§Ø³Øª Ùˆ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù…ÙˆØ±Ø¯ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.", 2),
    ("Ø¨Ù„Ù‡ØŒ Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø¯Ø± Ø³Ø§Ø²Ù…Ø§Ù† Ø¨Ù‡â€ŒØµÙˆØ±Øª Ú©Ø§Ù…Ù„ Ùˆ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.", 3),
    ("Ø¨Ù„Ù‡ØŒ Ú†Ù†Ø¯ Ø³Ø§Ù„ Ø§Ø³Øª Ú©Ù‡ Ù†ØªØ§ÛŒØ¬ Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† ØªØ¬Ø±Ø¨Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø³ØªÙ…Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯.", 4),
]
REL_OPTIONS = [
    ("Ù‡ÛŒÚ† Ø§Ø±ØªØ¨Ø§Ø·ÛŒ Ù†Ø¯Ø§Ø±Ø¯.", 1),
    ("Ø§Ø±ØªØ¨Ø§Ø· Ú©Ù… Ø¯Ø§Ø±Ø¯.", 3),
    ("ØªØ§ Ø­Ø¯ÛŒ Ù…Ø±ØªØ¨Ø· Ø§Ø³Øª.", 5),
    ("Ø§Ø±ØªØ¨Ø§Ø· Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯.", 7),
    ("Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ø±ØªØ¨Ø· Ø§Ø³Øª.", 10),
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ø¶Ø±Ø§ÛŒØ¨ ÙØ§Ø²ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Û´Û° Ù…ÙˆØ¶ÙˆØ¹ (Ø®Ù„Ø§ØµÙ‡â€ŒØ´Ø¯Ù‡ Ø§Ø² Ø¬Ø¯ÙˆÙ„ Ø´Ù…Ø§) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROLE_MAP_EN2FA = {
    "Senior Managers":"Ù…Ø¯ÛŒØ±Ø§Ù† Ø§Ø±Ø´Ø¯",
    "Executives":"Ù…Ø¯ÛŒØ±Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒÛŒ",
    "Supervisors/Sr Experts":"Ø³Ø±Ù¾Ø±Ø³ØªØ§Ù† / Ø®Ø¨Ø±Ú¯Ø§Ù†",
    "Technical Experts":"Ù…ØªØ®ØµØµØ§Ù† ÙÙ†ÛŒ",
    "Non-Technical Experts":"Ù…ØªØ®ØµØµØ§Ù† ØºÛŒØ± ÙÙ†ÛŒ",
}
# ØªÙˆØ¬Ù‡: Ø§ÛŒÙ† Ø¬Ø¯ÙˆÙ„ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù‡Ù…Ø§Ù† Â«NormalizedÂ»â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§Ø³Øª:
NORM_WEIGHTS = {
    1:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    2:{"Senior Managers":0.2692,"Executives":0.3846,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    3:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    4:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    5:{"Senior Managers":0.2692,"Executives":0.3846,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    6:{"Senior Managers":0.1923,"Executives":0.2692,"Supervisors/Sr Experts":0.1154,"Technical Experts":0.0385,"Non-Technical Experts":0.3846},
    7:{"Senior Managers":0.0385,"Executives":0.1923,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.3846,"Non-Technical Experts":0.1154},
    8:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    9:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1154,"Technical Experts":0.0385,"Non-Technical Experts":0.1923},
    10:{"Senior Managers":0.1154,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.0385,"Non-Technical Experts":0.3846},
    11:{"Senior Managers":0.1923,"Executives":0.3846,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    12:{"Senior Managers":0.1154,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.0385,"Non-Technical Experts":0.3846},
    13:{"Senior Managers":0.1154,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.0385,"Non-Technical Experts":0.3846},
    14:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    15:{"Senior Managers":0.1923,"Executives":0.3846,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    16:{"Senior Managers":0.1154,"Executives":0.1923,"Supervisors/Sr Experts":0.3846,"Technical Experts":0.2692,"Non-Technical Experts":0.0385},
    17:{"Senior Managers":0.1923,"Executives":0.3846,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    18:{"Senior Managers":0.2692,"Executives":0.3846,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    19:{"Senior Managers":0.1154,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.0385,"Non-Technical Experts":0.3846},
    20:{"Senior Managers":0.2692,"Executives":0.3846,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    21:{"Senior Managers":0.1154,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.0385,"Non-Technical Experts":0.3846},
    22:{"Senior Managers":0.2692,"Executives":0.3846,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    23:{"Senior Managers":0.1923,"Executives":0.3846,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    24:{"Senior Managers":0.0385,"Executives":0.1923,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.3846,"Non-Technical Experts":0.1154},
    25:{"Senior Managers":0.0385,"Executives":0.1923,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.3846,"Non-Technical Experts":0.1154},
    26:{"Senior Managers":0.1154,"Executives":0.1923,"Supervisors/Sr Experts":0.3846,"Technical Experts":0.2692,"Non-Technical Experts":0.0385},
    27:{"Senior Managers":0.1154,"Executives":0.1923,"Supervisors/Sr Experts":0.3846,"Technical Experts":0.2692,"Non-Technical Experts":0.0385},
    28:{"Senior Managers":0.1154,"Executives":0.1923,"Supervisors/Sr Experts":0.3846,"Technical Experts":0.2692,"Non-Technical Experts":0.0385},
    29:{"Senior Managers":0.1923,"Executives":0.3846,"Supervisors/Sr Experts":0.0385,"Technical Experts":0.1154,"Non-Technical Experts":0.2692},
    30:{"Senior Managers":0.1154,"Executives":0.3846,"Supervisors/Sr Experts":0.0385,"Technical Experts":0.2692,"Non-Technical Experts":0.1923},
    31:{"Senior Managers":0.1154,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.0385,"Non-Technical Experts":0.3846},
    32:{"Senior Managers":0.0385,"Executives":0.2692,"Supervisors/Sr Experts":0.1154,"Technical Experts":0.3846,"Non-Technical Experts":0.1923},
    33:{"Senior Managers":0.0385,"Executives":0.1923,"Supervisors/Sr Experts":0.1154,"Technical Experts":0.3846,"Non-Technical Experts":0.2692},
    34:{"Senior Managers":0.0385,"Executives":0.2692,"Supervisors/Sr Experts":0.1154,"Technical Experts":0.3846,"Non-Technical Experts":0.1923},
    35:{"Senior Managers":0.0385,"Executives":0.1923,"Supervisors/Sr Experts":0.1154,"Technical Experts":0.3846,"Non-Technical Experts":0.2692},
    36:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1923,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    37:{"Senior Managers":0.0385,"Executives":0.2692,"Supervisors/Sr Experts":0.3846,"Technical Experts":0.1923,"Non-Technical Experts":0.1154},
    38:{"Senior Managers":0.0385,"Executives":0.2692,"Supervisors/Sr Experts":0.3846,"Technical Experts":0.1923,"Non-Technical Experts":0.1154},
    39:{"Senior Managers":0.1923,"Executives":0.3846,"Supervisors/Sr Experts":0.2692,"Technical Experts":0.1154,"Non-Technical Experts":0.0385},
    40:{"Senior Managers":0.3846,"Executives":0.2692,"Supervisors/Sr Experts":0.1154,"Technical Experts":0.0385,"Non-Technical Experts":0.1923},
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ú©Ù…Ú©â€ŒØªØ§Ø¨Ø¹â€ŒÙ‡Ø§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ensure_company(company: str):
    (DATA_DIR / company).mkdir(parents=True, exist_ok=True)

def load_company_df(company: str) -> pd.DataFrame:
    ensure_company(company)
    p = DATA_DIR / company / "responses.csv"
    if p.exists():
        return pd.read_csv(p)
    cols = ["timestamp","company","respondent","role"]
    for t in TOPICS:
        cols += [f"t{t['id']}_maturity", f"t{t['id']}_rel", f"t{t['id']}_adj"]
    return pd.DataFrame(columns=cols)

def save_response(company: str, record: dict):
    df_old = load_company_df(company)
    df_new = pd.concat([df_old, pd.DataFrame([record])], ignore_index=True)
    df_new.to_csv(DATA_DIR / company / "responses.csv", index=False)

def normalize_adj_to_100(x):
    return (x/40.0)*100.0 if pd.notna(x) else np.nan

def _angles_deg_40():
    base = np.arange(0, 360, 360/40.0)  # 0..351
    return (base + 90) % 360  # Ø±Ø£Ø³ Ø§ÙˆÙ„ Ø¨Ø§Ù„Ø§

def plot_radar(series_dict, title, tick_names, target=45, annotate=False, show_legend=True):
    N = len(tick_names)
    angles_deg = _angles_deg_40()
    fig = go.Figure()
    for label, values in series_dict.items():
        vals = list(values)
        if len(vals)!=N: vals = (vals + [None]*N)[:N]
        vals_closed = vals + [vals[0]]
        theta_closed = angles_deg.tolist() + [angles_deg[0]]
        fig.add_trace(go.Scatterpolar(
            r=vals_closed, theta=theta_closed, thetaunit="degrees",
            mode="lines+markers"+("+text" if annotate else ""),
            name=label,
            text=[f"{v:.0f}" if v is not None else "" for v in vals_closed] if annotate else None,
            textposition="top center",
            line=dict(width=2),
            marker=dict(size=6, line=dict(width=1), color=ROLE_COLORS.get(label, None))
        ))
    # Ø®Ø·/Ø¨Ø§Ù†Ø¯ Ù‡Ø¯Ù
    fig.add_trace(go.Scatterpolar(
        r=[target]*(N+1), theta=angles_deg.tolist()+[angles_deg[0]], thetaunit="degrees",
        mode="lines", name=f"Ù‡Ø¯Ù {target}", line=dict(dash="dash", width=3, color="#444"), hoverinfo="skip"
    ))
    fig.update_layout(
        template=PLOTLY_TEMPLATE, font=dict(family="Vazir, Vazirmatn"),
        polar=dict(
            radialaxis=dict(visible=True, range=[0,100], dtick=10, gridcolor="#e6ecf5"),
            angularaxis=dict(thetaunit="degrees", direction="clockwise", rotation=0,
                             tickmode="array", tickvals=angles_deg.tolist(), ticktext=tick_names,
                             gridcolor="#edf2fb"),
            bgcolor="white"
        ),
        paper_bgcolor="#ffffff",
        showlegend=show_legend,
        legend=dict(orientation="h", yanchor="bottom", y=-0.2),
        margin=dict(t=60,b=90,l=10,r=10)
    )
    st.plotly_chart(fig, use_container_width=True)

def plot_bars_multirole(per_role_norm_fa: dict, topic_names, title, target=45):
    x = [f"{i+1:02d} â€” {n}" for i,n in enumerate(topic_names)]
    fig = go.Figure()
    for label, vals in per_role_norm_fa.items():
        fig.add_trace(go.Bar(x=x, y=vals, name=label, marker_color=ROLE_COLORS.get(label)))
    fig.update_layout(
        template=PLOTLY_TEMPLATE, font=dict(family="Vazir, Vazirmatn"),
        title=title, xaxis_title="Ù…ÙˆØ¶ÙˆØ¹", yaxis_title="Ù†Ù…Ø±Ù‡ (0..100)",
        xaxis=dict(tickfont=dict(size=10)), barmode="group",
        legend=dict(orientation="h", yanchor="bottom", y=-0.25),
        margin=dict(t=60,b=140,l=10,r=10), paper_bgcolor="#ffffff"
    )
    # Ø¨Ø§Ù†Ø¯ Ù‡Ø¯Ù Â±5
    fig.add_shape(type="rect", xref="paper", yref="y", x0=0, x1=1, y0=target-5, y1=target+5,
                  fillcolor="rgba(255,0,0,0.06)", line_width=0)
    fig.add_hline(y=target, line_dash="dash", line_color="red",
                  annotation_text=f"Ù‡Ø¯Ù {target}", annotation_position="top left")
    st.plotly_chart(fig, use_container_width=True)

def plot_lines_multirole(per_role_norm_fa: dict, title, target=45):
    x = [f"{i+1:02d}" for i in range(40)]
    fig = go.Figure()
    for label, vals in per_role_norm_fa.items():
        fig.add_trace(go.Scatter(x=x, y=vals, mode="lines+markers", name=label,
                                 line=dict(width=2, color=ROLE_COLORS.get(label))))
    fig.update_layout(template=PLOTLY_TEMPLATE, font=dict(family="Vazir, Vazirmatn"),
                      title=title, xaxis_title="Ù…ÙˆØ¶ÙˆØ¹ (01..40)", yaxis_title="Ù†Ù…Ø±Ù‡ (0..100)",
                      paper_bgcolor="#ffffff", hovermode="x unified")
    fig.add_shape(type="rect", xref="paper", yref="y", x0=0, x1=1, y0=target-5, y1=target+5,
                  fillcolor="rgba(255,0,0,0.06)", line_width=0)
    fig.add_hline(y=target, line_dash="dash", line_color="red",
                  annotation_text=f"Ù‡Ø¯Ù {target}", annotation_position="top left")
    st.plotly_chart(fig, use_container_width=True)

def org_weighted_topic(per_role_norm_fa: dict, topic_id: int):
    """Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ Ø³Ø§Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù…ÙˆØ¶ÙˆØ¹ Â«topic_idÂ» Ø¨Ø§ Ø¶Ø±Ø§ÛŒØ¨ ÙØ§Ø²ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡."""
    w = NORM_WEIGHTS.get(topic_id, {})
    num=0.0; den=0.0
    for en_key, weight in w.items():
        fa_role = ROLE_MAP_EN2FA[en_key]
        vlist = per_role_norm_fa.get(fa_role, [])
        idx = topic_id-1
        if idx < len(vlist) and pd.notna(vlist[idx]):
            num += weight * vlist[idx]; den += weight
    return np.nan if den==0 else num/den

def get_company_logo_path(company: str) -> Path|None:
    folder = DATA_DIR / company
    for ext in ("png","jpg","jpeg"):
        p = folder / f"logo.{ext}"
        if p.exists(): return p
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± Ø¹Ù…ÙˆÙ…ÛŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ø¨Ø±Ù†Ø¯ÛŒÙ†Ú¯")
# Ù„ÙˆÚ¯ÙˆÛŒ Ù‡Ù„Ø¯ÛŒÙ†Ú¯ (Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± assets)
holding_logo_file = st.sidebar.file_uploader("Ù„ÙˆÚ¯ÙˆÛŒ Ù‡Ù„Ø¯ÛŒÙ†Ú¯ Ø§Ù†Ø±Ú˜ÛŒ Ú¯Ø³ØªØ± Ø³ÛŒÙ†Ø§", type=["png","jpg","jpeg"])
if holding_logo_file:
    (ASSETS_DIR / "holding_logo.png").write_bytes(holding_logo_file.getbuffer())
holding_logo_path = ASSETS_DIR / "holding_logo.png"

TARGET = st.sidebar.slider("ğŸ¯ Ø®Ø· Ù‡Ø¯Ù (0..100)", 0, 100, 45, 1)
annotate_radar = st.sidebar.checkbox("Ù†Ù…Ø§ÛŒØ´ Ø§Ø¹Ø¯Ø§Ø¯ Ø±ÙˆÛŒ Ù†Ù‚Ø§Ø· Ø±Ø§Ø¯Ø§Ø±", value=False)

tabs = st.tabs(["ğŸ“ Ù¾Ø±Ø³Ø´Ù†Ø§Ù…Ù‡","ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ØªØ¨ Ù¾Ø±Ø³Ø´Ù†Ø§Ù…Ù‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tabs[0]:
    # Ù‡Ø¯Ø±: Ù„ÙˆÚ¯ÙˆÛŒ Ù‡Ù„Ø¯ÛŒÙ†Ú¯ + Ø¹Ù†ÙˆØ§Ù†
    col_logo, col_title = st.columns([1,5], vertical_alignment="center")
    with col_logo:
        if holding_logo_path.exists():
            st.image(str(holding_logo_path), width=130)
    with col_title:
        st.markdown("## Ù¾Ø±Ø³Ø´Ù†Ø§Ù…Ù‡ ØªØ¹ÛŒÛŒÙ† Ø³Ø·Ø­ Ø¨Ù„ÙˆØº Ù‡Ù„Ø¯ÛŒÙ†Ú¯ Ø§Ù†Ø±Ú˜ÛŒ Ú¯Ø³ØªØ± Ø³ÛŒÙ†Ø§ Ùˆ Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ÛŒ ØªØ§Ø¨Ø¹Ù‡ Ø¯Ø± Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø±Ø§ÛŒÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ")

    st.info("Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…ÙˆØ¶ÙˆØ¹ Ø§Ø¨ØªØ¯Ø§ ØªÙˆØ¶ÛŒØ­ ÙØ§Ø±Ø³ÛŒ Ø¢Ù† Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†ÛŒØ¯ØŒ Ø³Ù¾Ø³ Ø¨Ù‡ Ø¯Ùˆ Ù¾Ø±Ø³Ø´ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯.")

    company = st.text_input("Ù†Ø§Ù… Ø´Ø±Ú©Øª")
    respondent = st.text_input("Ù†Ø§Ù… Ùˆ Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)")
    role = st.selectbox("Ù†Ù‚Ø´ / Ø±Ø¯Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ", ROLES)

    # ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    N_PER_PAGE = st.sidebar.number_input("ØªØ¹Ø¯Ø§Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ø¯Ø± Ù‡Ø± ØµÙØ­Ù‡", 5, 40, 8, step=1)
    total_pages = int(np.ceil(len(TOPICS)/N_PER_PAGE))
    page_idx = st.sidebar.number_input("ØµÙØ­Ù‡", 1, max(1,total_pages), 1, step=1) - 1
    start, end = page_idx * N_PER_PAGE, min(page_idx * N_PER_PAGE + N_PER_PAGE, len(TOPICS))
    st.caption(f"Ù†Ù…Ø§ÛŒØ´ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª {start+1} ØªØ§ {end} Ø§Ø² {len(TOPICS)}")

    answers = {}
    for t in TOPICS[start:end]:
        with st.expander(f"{t['id']:02d} â€” {t['name']}", expanded=False):
            st.markdown(f'''
            <div class="question-card">
              <div class="q-head"><span class="q-num">{t["id"]:02d}</span>{t["name"]}</div>
              <div class="q-desc">{t["desc"].replace("\n","<br>")}</div>
            </div>
            ''', unsafe_allow_html=True)
            m_choice = st.radio(f"Û±) Ø¨Ù‡ Ù†Ø¸Ø± Ø´Ù…Ø§ØŒ Ù…ÙˆØ¶ÙˆØ¹ Â«{t['name']}Â» Ø¯Ø± Ø³Ø§Ø²Ù…Ø§Ù† Ø´Ù…Ø§ Ø¯Ø± Ú†Ù‡ Ø³Ø·Ø­ÛŒ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯ØŸ",
                                options=[opt for (opt,_) in LEVEL_OPTIONS], key=f"mat_{t['id']}")
            r_choice = st.radio(f"Û²) Ù…ÙˆØ¶ÙˆØ¹ Â«{t['name']}Â» Ú†Ù‚Ø¯Ø± Ø¨Ù‡ Ø­ÛŒØ·Ù‡ Ú©Ø§Ø±ÛŒ Ø´Ù…Ø§ Ø§Ø±ØªØ¨Ø§Ø· Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø§Ø±Ø¯ØŸ",
                                options=[opt for (opt,_) in REL_OPTIONS], key=f"rel_{t['id']}")
            answers[t['id']] = (m_choice, r_choice)

    # Ø«Ø¨Øª Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§
    if st.button("Ø«Ø¨Øª Ù¾Ø§Ø³Ø®"):
        if not company:
            st.error("Ù†Ø§Ù… Ø´Ø±Ú©Øª Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
        elif not role:
            st.error("Ù†Ù‚Ø´/Ø±Ø¯Ù‡ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.")
        elif len(answers) < len(TOPICS):  # Ú†ÙˆÙ† ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø¨Ø§ÛŒØ¯ Ú©Ù„ ØµÙØ­Ø§Øª ØªÚ©Ù…ÛŒÙ„ Ø´ÙˆÙ†Ø¯
            st.warning("Ø´Ù…Ø§ ÙÙ‚Ø· Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø±Ø§ Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯ÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ù‡Ù…Ù‡ ØµÙØ­Ø§Øª Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ùˆ Ø³Ù¾Ø³ Ø«Ø¨Øª Ú©Ù†ÛŒØ¯.")
        else:
            ensure_company(company)
            rec = {"timestamp": datetime.now().isoformat(timespec="seconds"),
                   "company": company, "respondent": respondent, "role": role}
            for t in TOPICS:
                m_choice = answers.get(t['id'], (LEVEL_OPTIONS[0][0], REL_OPTIONS[0][0]))[0]
                r_choice = answers.get(t['id'], (LEVEL_OPTIONS[0][0], REL_OPTIONS[0][0]))[1]
                mat = dict(LEVEL_OPTIONS)[m_choice]
                rel = dict(REL_OPTIONS)[r_choice]
                adj = mat * rel
                rec[f"t{t['id']}_maturity"] = mat
                rec[f"t{t['id']}_rel"] = rel
                rec[f"t{t['id']}_adj"] = adj
            save_response(company, rec)
            st.success("âœ… Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ØªØ¨ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tabs[1]:
    st.subheader("ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù†ØªØ§ÛŒØ¬")

    # ÙˆØ±ÙˆØ¯ Ø¨Ø§ Ø±Ù…Ø²
    password = st.text_input("ğŸ”‘ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯", type="password")
    if password != "Emacraven110":
        st.error("Ø¯Ø³ØªØ±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ø§Ø³Øª. Ø±Ù…Ø² Ø¹Ø¨ÙˆØ± Ø¯Ø±Ø³Øª Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
        st.stop()

    # Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø±Ú©Øª
    companies = sorted([d.name for d in DATA_DIR.iterdir() if d.is_dir()])
    if not companies:
        st.warning("Ù‡Ù†ÙˆØ² Ù‡ÛŒÚ† Ù¾Ø§Ø³Ø®ÛŒ Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        st.stop()
    company = st.selectbox("Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø±Ú©Øª", companies)

    # Ù†Ù…Ø§ÛŒØ´ Ù„ÙˆÚ¯ÙˆÙ‡Ø§
    row_logo = st.columns([1, 1, 6])
    with row_logo[0]:
        if holding_logo_path.exists():
            st.image(str(holding_logo_path), width=100, caption="Ù‡Ù„Ø¯ÛŒÙ†Ú¯ Ø§Ù†Ø±Ú˜ÛŒ Ú¯Ø³ØªØ± Ø³ÛŒÙ†Ø§")
    with row_logo[1]:
        st.caption("Ù„ÙˆÚ¯ÙˆÛŒ Ø´Ø±Ú©Øª Ù…Ù†ØªØ®Ø¨:")
        comp_logo_file = st.file_uploader("Ø¢Ù¾Ù„ÙˆØ¯/Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÙˆÚ¯ÙˆÛŒ Ø´Ø±Ú©Øª", key="uplogo", type=["png","jpg","jpeg"])
        if comp_logo_file:
            ensure_company(company)
            # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ Ù†Ø§Ù… Ø«Ø§Ø¨Øª
            (DATA_DIR / company / "logo.png").write_bytes(comp_logo_file.getbuffer())
        comp_logo_path = get_company_logo_path(company)
        if comp_logo_path:
            st.image(str(comp_logo_path), width=100, caption=company)

    df = load_company_df(company)
    if df.empty:
        st.warning("Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø´Ø±Ú©Øª Ù¾Ø§Ø³Ø®ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        st.stop()

    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ù…ØªÛŒØ§Ø²Ù‡Ø§ (0..40 -> 0..100)
    adj_cols = [f"t{t['id']}_adj" for t in TOPICS]
    df_norm = df.copy()
    for c in adj_cols: df_norm[c] = df_norm[c].apply(normalize_adj_to_100)

    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ù†Ù‚Ø´
    role_means = {}
    for role in ROLES:
        sub = df_norm[df_norm["role"]==role]
        if sub.empty:
            role_means[role] = [np.nan]*len(TOPICS)
        else:
            role_means[role] = [sub[f"t{t['id']}_adj"].mean() for t in TOPICS]

    # ÙÛŒÙ„ØªØ± Ù†Ù‚Ø´â€ŒÙ‡Ø§ Ùˆ Ø¨Ø§Ø²Ù‡ Ù…ÙˆØ¶ÙˆØ¹â€ŒÙ‡Ø§
    roles_selected = st.multiselect("ğŸš Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ù†Ù…Ø§ÛŒØ´", ROLES, default=ROLES)
    topic_range = st.slider("Ø¨Ø§Ø²Ù‡Ù” Ù…ÙˆØ¶ÙˆØ¹â€ŒÙ‡Ø§", 1, 40, (1,40))
    idx0, idx1 = topic_range[0]-1, topic_range[1]
    topics_slice = TOPICS[idx0:idx1]
    topic_names_slice = [t['name'] for t in topics_slice]

    role_means_filtered = {
        r: role_means[r][idx0:idx1] for r in roles_selected
    }

    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ²Ù†ÛŒ ÙØ§Ø²ÛŒ Ø³Ø§Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…ÙˆØ¶ÙˆØ¹
    per_role_norm_fa = {r: role_means[r] for r in ROLES}
    org_series_full = [org_weighted_topic(per_role_norm_fa, t["id"]) for t in TOPICS]
    org_series = org_series_full[idx0:idx1]

    # KPI Ù‡Ø§
    org_avg = np.nanmean(org_series_full)
    pass_rate = np.mean([1 if (v>=TARGET) else 0 for v in org_series_full if pd.notna(v)])*100
    # Ø¨Ù‡ØªØ±ÛŒÙ†/Ø¶Ø¹ÛŒÙâ€ŒØªØ±ÛŒÙ† (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ù†Ù‚Ø´â€ŒÙ‡Ø§)
    simple_means = []
    for i, t in enumerate(TOPICS):
        vals = [role_means[r][i] for r in ROLES if pd.notna(role_means[r][i])]
        simple_means.append(np.nanmean(vals) if vals else np.nan)
    best_idx = int(np.nanargmax(simple_means)) if np.isfinite(np.nanmax(simple_means)) else None
    worst_idx = int(np.nanargmin(simple_means)) if np.isfinite(np.nanmin(simple_means)) else None
    best_label = f"{best_idx+1:02d} â€” {TOPICS[best_idx]['name']}" if best_idx is not None else "-"
    worst_label = f"{worst_idx+1:02d} â€” {TOPICS[worst_idx]['name']}" if worst_idx is not None else "-"

    k1,k2,k3,k4 = st.columns(4)
    k1.markdown(f"""<div class="kpi"><div class="title">Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø²Ù…Ø§Ù† (ÙØ§Ø²ÛŒ)</div>
    <div class="value">{(org_avg if pd.notna(org_avg) else 0):.1f}</div><div class="sub">Ø§Ø² 100</div></div>""", unsafe_allow_html=True)
    k2.markdown(f"""<div class="kpi"><div class="title">Ù†Ø±Ø® Ø¹Ø¨ÙˆØ± Ø§Ø² Ù‡Ø¯Ù</div>
    <div class="value">{pass_rate:.0f}%</div><div class="sub">Ù†Ù‚Ø§Ø· â‰¥ Ù‡Ø¯Ù</div></div>""", unsafe_allow_html=True)
    k3.markdown(f"""<div class="kpi"><div class="title">Ø¨Ù‡ØªØ±ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹</div>
    <div class="value">{best_label}</div><div class="sub">Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ù†Ù‚Ø´â€ŒÙ‡Ø§</div></div>""", unsafe_allow_html=True)
    k4.markdown(f"""<div class="kpi"><div class="title">Ø¶Ø¹ÛŒÙâ€ŒØªØ±ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹</div>
    <div class="value">{worst_label}</div><div class="sub">Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ù†Ù‚Ø´â€ŒÙ‡Ø§</div></div>""", unsafe_allow_html=True)

    # Top/Bottom 5 (Ø§Ø·Ù„Ø§Ø¹ Ù…Ú©Ù…Ù„)
    st.markdown("### ğŸ” Top 5 Ùˆ Bottom 5 (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ù†Ù‚Ø´â€ŒÙ‡Ø§)")
    topic_mean_series = pd.Series(simple_means, index=[f"{i+1:02d} â€” {t['name']}" for i,t in enumerate(TOPICS)])
    colA, colB = st.columns(2)
    colA.write("**Top 5**"); colA.table(topic_mean_series.sort_values(ascending=False).head(5).round(1))
    colB.write("**Bottom 5**"); colB.table(topic_mean_series.sort_values(ascending=True).head(5).round(1))

    # Ø±Ø§Ø¯Ø§Ø± ØªÚ©â€ŒÙ†Ù‚Ø´â€ŒÙ‡Ø§ (Ø±ÙˆÛŒ Ø¨Ø§Ø²Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ)
    st.markdown("### ğŸŒ Ø±Ø§Ø¯Ø§Ø± Û´Û°â€ŒØ¨Ø®Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ø¯Ù‡ (Ù†Ù…Ø±Ù‡ Ù†Ø±Ù…Ø§Ù„â€ŒØ´Ø¯Ù‡)")
    cols = st.columns(2)
    tick_full_slice = [f"{i+idx0+1:02d} â€” {t['name']}" for i,t in enumerate(topics_slice)]
    c_idx=0
    for fa in roles_selected:
        vals = role_means_filtered.get(fa, [])
        if not vals or all(pd.isna(vals)): continue
        with cols[c_idx%2]:
            plot_radar({fa: vals}, f"Ø±Ø§Ø¯Ø§Ø± â€” {fa}", tick_full_slice, target=TARGET, annotate=annotate_radar, show_legend=False)
        c_idx+=1
    if c_idx==0:
        st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±Ø³ÛŒÙ… Ø±Ø§Ø¯Ø§Ø± ØªÚ©â€ŒÙ†Ù‚Ø´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

    # Ø±Ø§Ø¯Ø§Ø± ØªØ±Ú©ÛŒØ¨ÛŒ Ù†Ù‚Ø´â€ŒÙ‡Ø§
    st.markdown("### ğŸŒ Ø±Ø§Ø¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ Ù†Ù‚Ø´â€ŒÙ‡Ø§")
    overlay = {fa: role_means_filtered[fa] for fa in roles_selected if any(pd.notna(x) for x in role_means_filtered[fa])}
    if overlay:
        plot_radar(overlay, "Ø±Ø§Ø¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ Ù†Ù‚Ø´â€ŒÙ‡Ø§", tick_full_slice, target=TARGET, annotate=False, show_legend=True)
    else:
        st.info("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ø¯Ø§Ø± ØªØ¬Ù…ÛŒØ¹ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

    # Ø±Ø§Ø¯Ø§Ø± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø²Ù…Ø§Ù†Ù ÙØ§Ø²ÛŒ
    st.markdown("### ğŸ›ï¸ Ø±Ø§Ø¯Ø§Ø± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø²Ù…Ø§Ù† (ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ ÙØ§Ø²ÛŒ)")
    plot_radar({"Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø²Ù…Ø§Ù†": org_series}, "Ø±Ø§Ø¯Ø§Ø± â€” Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø²Ù…Ø§Ù† (ÙØ§Ø²ÛŒ)", tick_full_slice,
               target=TARGET, annotate=annotate_radar, show_legend=False)

    # Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ù†Ù‚Ø´â€ŒÙ‡Ø§
    st.markdown("### ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ (Ù†Ù‚Ø´â€ŒÙ‡Ø§)")
    plot_bars_multirole({r:role_means[r][idx0:idx1] for r in roles_selected},
                        topic_names_slice, "Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±Ø¯Ù‡â€ŒÙ‡Ø§ (0..100)", target=TARGET)

    # Ø®Ø·ÛŒ Ù†Ù‚Ø´â€ŒÙ‡Ø§
    st.markdown("### ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø®Ø·ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ")
    plot_lines_multirole({r:role_means[r][idx0:idx1] for r in roles_selected},
                         "Line Chart â€” Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±Ø¯Ù‡â€ŒÙ‡Ø§", target=TARGET)

    # Heatmap
    st.markdown("### ğŸ”¥ Heatmap Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ã— Ù†Ù‚Ø´â€ŒÙ‡Ø§ (0..100)")
    heat_df = pd.DataFrame({ "Ù…ÙˆØ¶ÙˆØ¹":[f"{i+idx0+1:02d} â€” {t['name']}" for i,t in enumerate(topics_slice)] })
    for fa in roles_selected:
        heat_df[fa] = role_means[fa][idx0:idx1]
    heat_melt = heat_df.melt(id_vars="Ù…ÙˆØ¶ÙˆØ¹", var_name="Ù†Ù‚Ø´", value_name="Ø§Ù…ØªÛŒØ§Ø²")
    fig_heat = px.density_heatmap(heat_melt, x="Ù†Ù‚Ø´", y="Ù…ÙˆØ¶ÙˆØ¹", z="Ø§Ù…ØªÛŒØ§Ø²",
                                  color_continuous_scale="RdYlGn", height=600, template=PLOTLY_TEMPLATE)
    st.plotly_chart(fig_heat, use_container_width=True)

    # Boxplot
    st.markdown("### ğŸ“¦ Boxplot ØªÙˆØ²ÛŒØ¹ Ù†Ù…Ø±Ø§Øª")
    fig_box = px.box(heat_melt.dropna(), x="Ù†Ù‚Ø´", y="Ø§Ù…ØªÛŒØ§Ø²", points="all", color="Ù†Ù‚Ø´",
                     color_discrete_map=ROLE_COLORS, template=PLOTLY_TEMPLATE)
    st.plotly_chart(fig_box, use_container_width=True)

    # Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ùˆ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    st.markdown("### ğŸ”— Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ùˆ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ")
    corr_base = heat_df.set_index("Ù…ÙˆØ¶ÙˆØ¹")[roles_selected]
    if not corr_base.empty:
        corr = corr_base.T.corr()
        fig_corr = px.imshow(corr, text_auto=True, color_continuous_scale="RdBu_r",
                             aspect="auto", height=700, template=PLOTLY_TEMPLATE)
        st.plotly_chart(fig_corr, use_container_width=True)
    if SKLEARN_OK and corr_base.notna().any().any():
        k = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§ (K)", 2, 6, 3)
        X = corr_base.fillna(corr_base.mean()).values
        km = KMeans(n_clusters=k, n_init=10, random_state=42).fit(X)
        clusters = km.labels_
        cl_df = pd.DataFrame({
            "Ù…ÙˆØ¶ÙˆØ¹":corr_base.index,
            "Ø®ÙˆØ´Ù‡":clusters
        }).sort_values("Ø®ÙˆØ´Ù‡")
        st.dataframe(cl_df, use_container_width=True)
    else:
        st.caption('<span class="small-note">Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ù‡ scikit-learn Ùˆ Ø¯Ø§Ø¯Ù‡Ù” Ú©Ø§ÙÛŒ Ù†ÛŒØ§Ø² Ø§Ø³Øª.</span>', unsafe_allow_html=True)

    # Ø¯Ø§Ù†Ù„ÙˆØ¯Ù‡Ø§
    st.markdown("### â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    st.download_button("Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø´Ø±Ú©Øª",
                       data=load_company_df(company).to_csv(index=False).encode("utf-8-sig"),
                       file_name=f"{company}_responses.csv", mime="text/csv")
    # Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† kaleido Ù†ØµØ¨ Ú©Ø±Ø¯ Ùˆ Ø§Ø² fig.to_image Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÙˆØ¯.
    st.caption('Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ØŒ Ø¨Ø³ØªÙ‡Ù” `kaleido` Ø±Ø§ Ø¨Ù‡ requirements Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø² `fig.to_image("png")` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.')
